Chat Bot Application Documentation
This documentation provides an overview of the Chat Bot application, implemented using Streamlit and Google Generative AI.

Overview
The Chat Bot application enables users to input questions and receive detailed responses generated by the Google Generative AI model. The application utilizes the Streamlit framework for the user interface and the google.generativeai library for generating responses.

Dependencies
streamlit
python-dotenv
google-generativeai
Ensure you have the required dependencies installed before running the application. You can install them using pip:

bash
Copy code
pip install streamlit python-dotenv google-generativeai
Configuration
The application uses environment variables to securely manage the API key required for accessing the Google Generative AI service. Ensure you have a .env file in the root directory of your project with the following content:

makefile
Copy code
GOOGLE_API_KEY=your_google_api_key
Code Explanation
Importing Libraries
python
Copy code
import streamlit as st
import os
from dotenv import load_dotenv
import google.generativeai as genai
The necessary libraries are imported. streamlit is used for building the web interface, os and dotenv for handling environment variables, and google.generativeai for interacting with the AI model.

Loading Environment Variables
python
Copy code
load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
Environment variables are loaded from the .env file, and the API key is configured for the Google Generative AI service.

Generating AI Response
python
Copy code
def ask_gemini(user_question):
    model = genai.GenerativeModel('gemini-pro')

    prompt = f'Given the user input provide the most appropriate highly detailed response also provide short examples if possible in text format only, thankyou. {user_question}'

    response_gemini = model.generate_content(prompt)
    response_gemini = response_gemini.text.replace('**', '').replace('*', 'â€¢')

    return response_gemini
The ask_gemini function takes a user question, generates a prompt, and obtains a response from the Google Generative AI model. The response text is formatted by replacing certain characters.

Formatting the Response
python
Copy code
def format_response(response):
    lines = response.split('â€¢')
    lines = [line.strip() for line in lines if line.strip()]
    formatted_lines = []
    for line in lines:
        if line.isdigit():
            formatted_lines.append(f"**{line}.**")
        else:
            formatted_lines.append(f"- {line}")
    return '\n'.join(formatted_lines)
The format_response function processes the AI response by splitting it into lines, stripping whitespace, and formatting each line for better readability.

Main Application Logic
python
Copy code
def main():
    st.set_page_config("Chat Bot")
    st.header("Chat BotðŸ¤–")

    user_question = st.text_input("Ask your question:", "")

    if st.button("Submit"):
        with st.spinner("Generating response..."):
            raw_gemini_response = ask_gemini(user_question)

            formatted_gemini_response = format_response(raw_gemini_response)

            st.markdown(formatted_gemini_response, unsafe_allow_html=True)
The main function sets up the Streamlit interface, including a text input for the user's question and a submit button. When the button is clicked, it generates a response using the AI model and displays it in a formatted manner.

Entry Point
python
Copy code
if __name__ == "__main__":
    main()
The entry point ensures the main function is executed when the script is run directly.

Running the Application
To run the Chat Bot application, execute the following command in your terminal:

bash
Copy code
streamlit run <script_name>.py
Replace <script_name> with the name of your Python script file.

This will start a local web server and open the Chat Bot application in your default web browser. You can then input your questions and receive responses generated by the Google Generative AI model.





